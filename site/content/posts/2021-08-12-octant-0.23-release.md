---
title: "Dead container walking: making a case for Kubernetes Object Status "
image: /img/posts/2021/08/18/octantStatus03.png
excerpt: With release 0.23, Octant is a more accurate tool for troubleshooting scenarios
author: David Espejo
author_avatar: /img/contributors/david-espejo.jpg
date: 2021-08-31
categories: ['kubernetes']
tags: ['octant', 'release', 'David Espejo']
slug: octant-object-status
---
As an application developer, you may be familiar with kubectl and how to interpret the results you get from a very common command like:
```
    # kubectl get pods
    # NAME                                      READY   STATUS    RESTARTS   AGE
    3scale-kourier-control-54cc54cc58-px2dt   1/1     Running   3          4d2h
    activator-67656dcbbb-hq62r                0/1     Running   161        4d2h
    autoscaler-df6856b64-blxgm                1/1     Running   1          4d2h
   ```
But in case you are not, it could be challenging to accurately diagnose an issue when you see -according to the above example- that the "activator" Pod is in a Running *status* but 0 of its containers are Ready. 

How could it be?

It all comes to how the Kubernetes API handles Pod lifecycle

# POD lifecycle details

According to the [oficial docs](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/), the Kubernetes API has a PodStatus object with a field called **Phase** but there's also the container **State** field that Kubernetes tracks. The difference between the two lies in the level the API server is reffering to: the Pod or the container respectively.

While there are five possible values for Pod phase:

| Value | Description |
| :----:  | ----- |
| Pending | Configuration accepted by the server but not ready to run (e.g. init containers, pending image fetching, among others) |
| Running | All of the Pod's containers created, at least one of them is running|
| Succeeded | All containers successfully completed their task and then exited, especially true in the presence of OnFailure [restartPolicy](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy) |
| Failed | All containers terminated and at least one terminated in failure|
| Unknown| Most likely the node is offline |

There are also three container states defined in the Kubernetes API:

| Value| Description|
| ----| ----|
|Waiting|   A task is pending to complete, for example a container image download or an init container still running|
|Running| Container executing with no issues nor pending tasks|
|Terminated| Container either ran to completion or it failed

So, coming back to our example: what kubectl is showing for the "activator" Pod is the **Phase** field (in this case **Running** as the container has been created) but the application there it's not usable yet. How could we determine more accurately the actual situation of the Pod?

Let's see:

# Octant and the Status field

Octant has always displayed the **Phase** field for each resource, but with the release of version 0.23, the team added the **Status** field which -in the case of Pods- refers specifically to the container State. 

So, if we take a look at the "activator" Pod with Octant:

![](/img/posts/2021/08/18/octantStatus01.png)

We can see that it's in the **Running** phase but the actual container state is **CrashLoopBackOff** which means that the Kubelet has succesfully started it several times but it has crashed afterwards without reaching a stable state yet.

We can get quickly to the root cause of the issue with Octant:

1. Click on the Pod name
2. Go to the **Resource Viewer** tab and there you will find the **Last Event** field:

![](/img/posts/2021/08/18/octantStatus02.png)

3. Finally, go to the **Logs** tab to gather even more details around the Readiness Probe failure:
```json
    {"severity":"ERROR","timestamp":"2021-08-31T21:08:56.7648856Z","logger":"activator","caller":"websocket/connection.go:145","message":"Websocket connection could not be established","commit":"c75484e","knative.dev/controller":"activator","knative.dev/pod":"activator-67656dcbbb-hq62r","error":"dial tcp 10.96.38.80:8080: connect: connection refused"}
```
There it is what seems to be root cause of the issue: a network connectivity problem. 

Always blame the network :) 

# Final thoughts and call to action

One of the [original goals of Octant](https://github.com/vmware-tanzu/octant/blob/master/ROADMAP.md) is to be a visual aid to kubectl to rapidly display the relationships between resources in your Kubernetes clusters and thus accelerate troubleshooting for cloud native applications. 
Leveraging all the details the Kubernetes API can provide in terms of Object Status is a stepping stone to fulfill that mission.

If you haven't, upgrade Octant to the latest version and let us know your thoughts, feature requests, issues and comments in the [Octant repo](https://github.com/vmware-tanzu/octant/issues/new/choose)

**Thank you!**

The Octant Community Management team

P.D.

If you are an Octant user, please consider adding a few details around your organization and use cases to [this discussion](https://github.com/vmware-tanzu/octant/discussions/2778) so we can promote you publicly as an Octant adopter!
______
